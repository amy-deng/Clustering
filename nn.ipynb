{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Songgaojun Deng 10442772\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# read csv file and renamed each column\n",
    "data = pd.read_csv('iris.data', header=None, names=['x1','x2','x3','x4','y'])\n",
    "\n",
    "# because our classes are strings, we should transform them to numeric representations for Neural Network Model\n",
    "data.loc[data[\"y\"] == \"Iris-setosa\",\"y\"] = 0\n",
    "data.loc[data[\"y\"] == \"Iris-versicolor\",\"y\"] = 1\n",
    "data.loc[data[\"y\"] == \"Iris-virginica\",\"y\"] = 2\n",
    "\n",
    "# splite data into training set and testing set with the rato 8:2\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:4].values, data.iloc[:,4].values, test_size=0.2, random_state=42)\n",
    "\n",
    "'''\n",
    "Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale our data. \n",
    "For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to \n",
    "have mean 0 and variance 1. And we must apply the same scaling to the test set for meaningful results. \n",
    "So I use StandardScaler of sklearn for standardization.\n",
    "'''\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "#Because K-Fold validation is used, so I set the number of folds in advance.\n",
    "kfold = KFold(5, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.000000 \t accuracy 0.875000\n",
      "alpha 0.001000 \t accuracy 0.958333\n",
      "alpha 0.002000 \t accuracy 0.875000\n",
      "alpha 0.003000 \t accuracy 0.916667\n",
      "alpha 0.004000 \t accuracy 0.958333\n",
      "alpha 0.005000 \t accuracy 0.958333\n",
      "alpha 0.006000 \t accuracy 0.958333\n",
      "alpha 0.007000 \t accuracy 0.958333\n",
      "alpha 0.008000 \t accuracy 0.875000\n",
      "alpha 0.009000 \t accuracy 0.916667\n",
      "alpha 0.010000 \t accuracy 0.916667\n",
      "alpha 0.011000 \t accuracy 0.916667\n",
      "alpha 0.012000 \t accuracy 0.958333\n",
      "alpha 0.013000 \t accuracy 0.875000\n",
      "alpha 0.014000 \t accuracy 0.875000\n",
      "alpha 0.015000 \t accuracy 0.958333\n",
      "alpha 0.016000 \t accuracy 0.958333\n",
      "alpha 0.017000 \t accuracy 0.875000\n",
      "alpha 0.018000 \t accuracy 0.916667\n",
      "alpha 0.019000 \t accuracy 0.875000\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list of learning rate. We should use K-fold validation to choose the best learning rate.\n",
    "alpha_list = []\n",
    "for i in range(20):\n",
    "    alpha_list.append(i * 0.001)\n",
    "\n",
    "val_acc_dict = {} # save the learning rate with its validation result for future model selection\n",
    "val_acc_list = [] # save all accuracy if each validation test, and for future average calculation\n",
    "model_dict = {} # save model with according learning rate\n",
    "\n",
    "# in this for-loop, we apply validation test to each learning rate\n",
    "for alpha in alpha_list:\n",
    "    \n",
    "    # in this for-loop, we apply K-fold validation test.\n",
    "    for train, val in kfold.split(X_train): # use K-fold validation\n",
    "        \n",
    "        # training the neural network model using sklearn package\n",
    "        clf = MLPClassifier(activation ='relu',solver='lbfgs', alpha=alpha, hidden_layer_sizes=(5, 2), random_state=1, validation_fraction=0)\n",
    "        clf.fit(X_train[train],y_train[train])\n",
    "        acc = clf.score(X_train[val],y_train[val]) # calculate accuracy in validation set\n",
    "        \n",
    "        model_dict[alpha] = clf\n",
    "        val_acc_list.append(acc)\n",
    "    val_acc_dict[alpha] = np.mean(val_acc_list) # calculate average accuracy for five fold\n",
    "    print(\"alpha %f \\t accuracy %f\" % (alpha, acc))   \n",
    "\n",
    "# select the best model whose validation set has greatest accuracy\n",
    "alpha = max(val_acc_dict, key=val_acc_dict.get)\n",
    "model = model_dict[alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " accuracy in testing set is 1.0\n",
      "\n",
      " accuracy in training set is 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "print '\\n accuracy in testing set is', model.score(X_test, y_test)\n",
    "print '\\n accuracy in training set is', model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
